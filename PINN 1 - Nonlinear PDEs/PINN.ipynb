{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn \n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "import pyDOE2\n",
    "from torch.autograd.functional import jacobian, hessian\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bounds = [-1, 1]\n",
    "t_bounds = [0, 1]\n",
    "num_data_points = 1000\n",
    "num_collocation_points = 10000\n",
    "proportion_t_0 = 0.4 #the proportion of the data points which will exist at various points x along the boundary t = 0. The rest will be split between the boundaries x = -1 and x = 1 for all t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_t_0 = (int) (num_data_points * proportion_t_0)\n",
    "num_points_x_1 = (num_data_points - num_points_t_0)//2 # // is integer division\n",
    "num_points_x_neg_1 = num_data_points - num_points_t_0 - num_points_x_1\n",
    "\n",
    "#create num_data_points random data points on the boundaries of the PDE\n",
    "t_0_points = np.array( list( zip(np.zeros(num_points_t_0), 2 * np.random.rand(num_points_t_0) - 1 ) ) )\n",
    "x_1_points = np.array( list( zip(np.random.rand(num_points_x_1), np.full(num_points_x_1, 1)) ) ) #np.full() takes paramters shape, value. Shape can be a tuple for multidimensional arrays filled with value.\n",
    "x_neg_1_points = np.array( list( zip(np.random.rand(num_points_x_neg_1), np.full(num_points_x_neg_1, -1)) ) )\n",
    "x_points = np.concatenate(( x_1_points, x_neg_1_points ))\n",
    "\n",
    "#Generating labels with the data\n",
    "dtype = [('points', float, 2), ('label', float)] #need custom dtype because otherwise numpy doesn't like these combined arrays\n",
    "\n",
    "t_0_labels = -np.sin(np.pi * t_0_points[:,1] )\n",
    "t_0_combined = np.array(list( zip(t_0_points, t_0_labels) ), dtype=dtype)\n",
    "\n",
    "x_labels = np.zeros(num_points_x_1 + num_points_x_neg_1)\n",
    "x_combined = np.array(list( zip(x_points, x_labels) ), dtype=dtype)\n",
    "\n",
    "combined_labels_data = np.concatenate( (t_0_combined, x_combined) )\n",
    "\n",
    "np.random.shuffle(combined_labels_data)\n",
    "\n",
    "data_points, labels = map(np.array, map(list, zip(*combined_labels_data)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Validation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Test 1: Ensure all data points lie on the correct boundaries\\ndef test_boundaries(data_points):\\n    t_values = data_points[:, 0]\\n    x_values = data_points[:, 1]\\n    assert np.all((t_values == 0) | (x_values == 1) | (x_values == -1)), \"Some points do not lie on the correct boundaries.\"\\n\\ntest_boundaries(data_points)\\nprint(\"Test 1 passed!\")\\n\\n# Test 2: For t=0, label should be -sin(pi * x)\\ndef test_labels_t_0(data_points, labels):\\n    mask_t_0 = data_points[:, 0] == 0\\n    expected_labels = -np.sin(np.pi * data_points[mask_t_0, 1])\\n    assert np.allclose(labels[mask_t_0], expected_labels), \"Labels for t=0 do not match -sin(pi * x).\"\\n\\ntest_labels_t_0(data_points, labels)\\nprint(\"Test 2 passed!\")\\n\\n# Test 3: For x=-1 or x=1, label should be 0\\ndef test_labels_x_boundaries(data_points, labels):\\n    mask_x_boundaries = (data_points[:, 1] == 1) | (data_points[:, 1] == -1)\\n    assert np.all(labels[mask_x_boundaries] == 0), \"Labels for x=-1 or x=1 are not zero.\"\\n\\ntest_labels_x_boundaries(data_points, labels)\\nprint(\"Test 3 passed!\")\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Test 1: Ensure all data points lie on the correct boundaries\n",
    "def test_boundaries(data_points):\n",
    "    t_values = data_points[:, 0]\n",
    "    x_values = data_points[:, 1]\n",
    "    assert np.all((t_values == 0) | (x_values == 1) | (x_values == -1)), \"Some points do not lie on the correct boundaries.\"\n",
    "\n",
    "test_boundaries(data_points)\n",
    "print(\"Test 1 passed!\")\n",
    "\n",
    "# Test 2: For t=0, label should be -sin(pi * x)\n",
    "def test_labels_t_0(data_points, labels):\n",
    "    mask_t_0 = data_points[:, 0] == 0\n",
    "    expected_labels = -np.sin(np.pi * data_points[mask_t_0, 1])\n",
    "    assert np.allclose(labels[mask_t_0], expected_labels), \"Labels for t=0 do not match -sin(pi * x).\"\n",
    "\n",
    "test_labels_t_0(data_points, labels)\n",
    "print(\"Test 2 passed!\")\n",
    "\n",
    "# Test 3: For x=-1 or x=1, label should be 0\n",
    "def test_labels_x_boundaries(data_points, labels):\n",
    "    mask_x_boundaries = (data_points[:, 1] == 1) | (data_points[:, 1] == -1)\n",
    "    assert np.all(labels[mask_x_boundaries] == 0), \"Labels for x=-1 or x=1 are not zero.\"\n",
    "\n",
    "test_labels_x_boundaries(data_points, labels)\n",
    "print(\"Test 3 passed!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN_DataSet(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "trainset = PINN_DataSet(data_points.astype(np.float32), labels.astype(np.float32)) #convert to float32, or else later the resulting torch tensors will be of torch.float64 type, which is not compatible with the neural network\n",
    "\n",
    "#batch_size = num_data_points #no mini-batches\n",
    "batch_size = 250\n",
    "\n",
    "num_workers = 0\n",
    "\n",
    "trainloader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = num_workers\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collocation Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lhs_samples(n): #generate n collocation points via Latin Hypercube Sampling. Each point is a (t,x)\n",
    "    lhs_array = pyDOE2.lhs(2, samples=n) #Two dimensions. Values from 0 to 1\n",
    "    lhs_array[:,1] = 2*lhs_array[:,1] - 1 #convert range of x values to -1 to 1\n",
    "    return lhs_array\n",
    "\n",
    "collocation_points = lhs_samples(num_collocation_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential( #9 layers of 20 neurons each\n",
    "            nn.Linear(2,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,1),\n",
    "            #nn.Tanh()\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_f(collocation_points, neural_network, device): #I need to better understand how exactly autograd handles vectorization. I think I just waste 6 hours on a wild goose chase due to a misconception about that very fact...\n",
    "\n",
    "    collocation_inputs = torch.tensor(collocation_points.astype(np.float32), requires_grad=True).to(device)\n",
    "    \n",
    "    u = neural_network(collocation_inputs)\n",
    "    results, = torch.autograd.grad(u, collocation_inputs, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)\n",
    "    u_t = results[:,0]\n",
    "    u_x = results[:,1]\n",
    "    snd_result, = torch.autograd.grad(u_x, collocation_inputs, grad_outputs=torch.ones_like(u_x), retain_graph=True, create_graph=True)\n",
    "    u_xx = snd_result[:,1]\n",
    "    return torch.mean((u_t + u*u_x - (0.01/torch.pi)*u_xx)**2)\n",
    "    \n",
    "def MSE_u(output, label):\n",
    "    return torch.mean((output - label)**2)\n",
    "\n",
    "\n",
    "def criterion(output, label, collocation_points, neural_network, device):\n",
    "    #mse_u = nn.MSELoss()(output, label).squeeze()\n",
    "    mse_u = MSE_u(output, label).squeeze()\n",
    "    mse_f = MSE_f(collocation_points, neural_network, device).squeeze()\n",
    "    return mse_u + mse_f, mse_u.item(), mse_f.item()\n",
    "    #return 10*(mse_u + mse_f), mse_u.item(), mse_f.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: CPU\n",
      "EPOCH 1 out of 50\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22889108955860138\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.950934240355309e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22866863012313843\n",
      "Avg f(t,x)^2 Per Collocation Point: 3.384925406635375e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.2262929379940033\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.222206584358901e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.1993127167224884\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.222206584358901e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.1993100643157959\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.24683328503761e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.1993100643157959\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.246625806558768e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.1686568707227707\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.246625806558768e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.16824352741241455\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.53900561581122e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.16824351251125336\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.538659936770273e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.23567155003547668\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.538659936770273e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.2356705367565155\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.538819808885819e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.23566603660583496\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.5395470493758694e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.23564280569553375\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.543082354757644e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.2355533242225647\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.545934828570353e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.2355533391237259\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.5448661722957695e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.2355533242225647\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.545900367247668e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.2355533242225647\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.545928788957099e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.2355533242225647\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.545934118027617e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.2355533242225647\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.545934118027617e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.2355533242225647\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.545934828570353e-08\n",
      "EPOCH 2 out of 50\n",
      "Avg MSE Loss Per Boundary Data Point: 0.20599636435508728\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.545934828570353e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.20591819286346436\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.5430269324242545e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.20591819286346436\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.541900722188075e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.18919965624809265\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.541900722188075e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.18919870257377625\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.5417976934913895e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.18919441103935242\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.5413294458285236e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.18917110562324524\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.53866206839848e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.1889553815126419\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.497717398521672e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.18873856961727142\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.313530865829307e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.18873856961727142\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.309840306859769e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22528396546840668\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.309840306859769e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22527089715003967\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.31235562814436e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22521217167377472\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.323624480662147e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22459125518798828\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.4397541643093064e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22089795768260956\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.831513322756109e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22069422900676727\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.785071539004093e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22069412469863892\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.7822389603879856e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22069412469863892\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.778346607281492e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22069412469863892\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.778303619445978e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22069412469863892\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.778302198360507e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.21255166828632355\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.778303619445978e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.21186259388923645\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.5766729073193346e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.21186257898807526\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.5735276898994925e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.21186259388923645\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.570276601612022e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.21186259388923645\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.5734154241472424e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.21186257898807526\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.573517387029824e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.21186257898807526\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.573526268814021e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.21186257898807526\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.5735273346281247e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.21186257898807526\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.5735276898994925e-08\n",
      "EPOCH 3 out of 50\n",
      "Avg MSE Loss Per Boundary Data Point: 0.17609718441963196\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.5735276898994925e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.17602099478244781\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.2575745595740955e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.176021009683609\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.2544851197590106e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.1760210245847702\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.2574328062983113e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.17602099478244781\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.257560703990748e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.17602099478244781\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.2575742043027276e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.17602099478244781\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.2575745595740955e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.17602099478244781\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.2575745595740955e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22541813552379608\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.2575745595740955e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22537408769130707\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.014569654486877e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22537408769130707\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.013846321981873e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.2309800386428833\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.013846321981873e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.229262575507164\n",
      "Avg f(t,x)^2 Per Collocation Point: 5.820320936322787e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22926250100135803\n",
      "Avg f(t,x)^2 Per Collocation Point: 5.8277326075995006e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22926250100135803\n",
      "Avg f(t,x)^2 Per Collocation Point: 5.818434800630712e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22926250100135803\n",
      "Avg f(t,x)^2 Per Collocation Point: 5.818342074803695e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22926250100135803\n",
      "Avg f(t,x)^2 Per Collocation Point: 5.8183413642609594e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.22926250100135803\n",
      "Avg f(t,x)^2 Per Collocation Point: 5.818341719532327e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.20104582607746124\n",
      "Avg f(t,x)^2 Per Collocation Point: 5.818342074803695e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.20104297995567322\n",
      "Avg f(t,x)^2 Per Collocation Point: 5.669024361054653e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.20101743936538696\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.655521479435265e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.2007557451725006\n",
      "Avg f(t,x)^2 Per Collocation Point: 1.445504835828615e-07\n",
      "Avg MSE Loss Per Boundary Data Point: 0.1991126388311386\n",
      "Avg f(t,x)^2 Per Collocation Point: 2.4409770205124914e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.19777725636959076\n",
      "Avg f(t,x)^2 Per Collocation Point: 8.57361465023132e-06\n",
      "Avg MSE Loss Per Boundary Data Point: 0.20201623439788818\n",
      "Avg f(t,x)^2 Per Collocation Point: 3.555391595000401e-05\n",
      "Avg MSE Loss Per Boundary Data Point: 0.1976039707660675\n",
      "Avg f(t,x)^2 Per Collocation Point: 1.567053004691843e-05\n",
      "Avg MSE Loss Per Boundary Data Point: 0.19752652943134308\n",
      "Avg f(t,x)^2 Per Collocation Point: 1.2484737453632988e-05\n",
      "Avg MSE Loss Per Boundary Data Point: 0.19726382195949554\n",
      "Avg f(t,x)^2 Per Collocation Point: 1.190001398754248e-06\n",
      "Avg MSE Loss Per Boundary Data Point: 0.19709336757659912\n",
      "Avg f(t,x)^2 Per Collocation Point: 1.7503314211353427e-06\n",
      "Avg MSE Loss Per Boundary Data Point: 0.19701088964939117\n",
      "Avg f(t,x)^2 Per Collocation Point: 3.3605266480662976e-07\n",
      "Avg MSE Loss Per Boundary Data Point: 0.19698405265808105\n",
      "Avg f(t,x)^2 Per Collocation Point: 3.1292525903836577e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.1969795674085617\n",
      "Avg f(t,x)^2 Per Collocation Point: 2.2559223822327112e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.19697587192058563\n",
      "Avg f(t,x)^2 Per Collocation Point: 3.897041622735742e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.19697581231594086\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.743520776173682e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.19697578251361847\n",
      "Avg f(t,x)^2 Per Collocation Point: 5.001868785825536e-08\n",
      "EPOCH 4 out of 50\n",
      "Avg MSE Loss Per Boundary Data Point: 0.2068779319524765\n",
      "Avg f(t,x)^2 Per Collocation Point: 5.001868785825536e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.20687656104564667\n",
      "Avg f(t,x)^2 Per Collocation Point: 5.969172178765803e-08\n",
      "Avg MSE Loss Per Boundary Data Point: 0.206869438290596\n",
      "Avg f(t,x)^2 Per Collocation Point: 1.1611147954226908e-07\n",
      "Avg MSE Loss Per Boundary Data Point: 0.20679683983325958\n",
      "Avg f(t,x)^2 Per Collocation Point: 6.221887360879919e-07\n",
      "Avg MSE Loss Per Boundary Data Point: 0.2067958116531372\n",
      "Avg f(t,x)^2 Per Collocation Point: 6.276110298131243e-07\n",
      "Avg MSE Loss Per Boundary Data Point: 0.20679067075252533\n",
      "Avg f(t,x)^2 Per Collocation Point: 6.541986294905655e-07\n",
      "Avg MSE Loss Per Boundary Data Point: 0.21190717816352844\n",
      "Avg f(t,x)^2 Per Collocation Point: 3.649798600235954e-06\n",
      "Avg MSE Loss Per Boundary Data Point: 0.2065991908311844\n",
      "Avg f(t,x)^2 Per Collocation Point: 8.502192940795794e-07\n",
      "Avg MSE Loss Per Boundary Data Point: 0.20657962560653687\n",
      "Avg f(t,x)^2 Per Collocation Point: 1.0146545719180722e-06\n",
      "Avg MSE Loss Per Boundary Data Point: 0.225917249917984\n",
      "Avg f(t,x)^2 Per Collocation Point: 4.7435682063223794e-05\n"
     ]
    }
   ],
   "source": [
    "pinn = PINN()\n",
    "optimizer = torch.optim.LBFGS(pinn.parameters(), #PARAMETERS CREDIT TO https://github.com/teeratornk/PINNs-2/blob/master/Burgers%20Equation/Burgers%20Inference%20(PyTorch).ipynb\n",
    "                              lr=1.0,\n",
    "                              max_iter=50000, \n",
    "                                max_eval=50000, \n",
    "                                history_size=50,\n",
    "                                tolerance_grad=1e-5, \n",
    "                                tolerance_change=1.0 * np.finfo(float).eps,\n",
    "                                line_search_fn=\"strong_wolfe\"\n",
    "                              )\n",
    "\n",
    "num_epochs = 50 #I have no idea how many epochs were used in the paper's implementation. Let's just do a lot for now and see how quickly training converges\n",
    "\n",
    "#use the GPU to train if possible, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + (\"GPU\" if torch.cuda.is_available() else \"CPU\"))\n",
    "pinn.to(device)\n",
    "\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print(f\"EPOCH {epoch + 1} out of {num_epochs}\")\n",
    "        train_running_loss = 0\n",
    "\n",
    "\n",
    "        for data in trainloader:\n",
    "\n",
    "            input, label = data #input and label already seem to be tensors. Tbh, I am a little confused when this happened. I don't think I ever explicitly turned them into tensors. They used to both be numpy arrays. EDIT: Further research seems to show that dataloader does this automatically as it fetches data from the dataset\n",
    "            input = input.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "\n",
    "            def closure():\n",
    "                optimizer.zero_grad() #reset the gradient so that the previous iteration does not affect the current one\n",
    "                output = pinn(input) #run the batch through the current model\n",
    "                loss, mse_u, mse_f = criterion(output, label, collocation_points, pinn, device) #calculate the loss\n",
    "                loss.backward() #Using backpropagation, calculate the gradients\n",
    "                print(f\"Avg MSE Loss Per Boundary Data Point: {mse_u}\")\n",
    "                print(f\"Avg f(t,x)^2 Per Collocation Point: {mse_f}\")\n",
    "                return loss\n",
    "\n",
    "            optimizer.step(closure) #Using the gradients, adjust the parameters    \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted by user.\")  \n",
    "\n",
    "print(\"TRAINING COMPLETE!\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "base_path = \"./\"\n",
    "base_name = \"pinn_model\"\n",
    "extension = \".pth\"\n",
    "\n",
    "counter = 0\n",
    "model_save_path = os.path.join(base_path, base_name + extension)\n",
    "\n",
    "while os.path.exists(model_save_path):\n",
    "    counter += 1\n",
    "    model_save_path = os.path.join(base_path, f\"{base_name}_{counter}{extension}\")\n",
    "\n",
    "torch.save(pinn.state_dict(), model_save_path)\n",
    "\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06639211]\n",
      " [-0.06632791]\n",
      " [-0.06654201]\n",
      " [-0.06661064]\n",
      " [-0.06605157]\n",
      " [-0.06689686]\n",
      " [-0.06703326]\n",
      " [-0.0663532 ]\n",
      " [-0.06656959]\n",
      " [-0.0666367 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Generate Random Points\n",
    "num_points = 10\n",
    "t_values = np.random.rand(num_points)\n",
    "x_values = np.random.uniform(-1, 1, num_points)\n",
    "points = np.vstack((t_values, x_values)).T\n",
    "points_tensor = torch.tensor(points, dtype=torch.float32).to(device)\n",
    "\n",
    "# 2. Feed the Points through the Model\n",
    "with torch.no_grad():\n",
    "    model_outputs = pinn(points_tensor).cpu().numpy()\n",
    "    print(model_outputs)\n",
    "\n",
    "# Normalize the model outputs to be between 0 and 1 for color mapping\n",
    "normalized_outputs = (model_outputs - (-1)) / (1 - (-1))\n",
    "\n",
    "# 3. Color Mapping\n",
    "colors = plt.cm.gray(normalized_outputs.squeeze()) # Change to grayscale\n",
    "\n",
    "# 4. Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(t_values, x_values, c=colors, s=1, alpha=0.5)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Visualization of Model Outputs\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-1-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
