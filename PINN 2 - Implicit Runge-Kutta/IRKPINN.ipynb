{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to self: I should defintely explore an object-oriented PyTorch approach in the future. It is annoying having to pass around every single required variable to helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn \n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.io\n",
    "\n",
    "from torch.autograd.functional import jacobian\n",
    "from torch.autograd.functional import hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of intermediate steps\n",
    "q = 500\n",
    "\n",
    "#step size\n",
    "h = 0.8\n",
    "\n",
    "#start and end location\n",
    "start_t = 0.1\n",
    "end_t = start_t + h\n",
    "\n",
    "N = 100 #number of x values for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata = scipy.io.loadmat('./data/burgers_shock.mat')\\n\\nt_points = data['t'].flatten()[:,None] # T x 1\\nx_points = data['x'].flatten()[:,None] # N x 1\\nExact = np.real(data['usol']).T # T x N\\n\\n#get data labels at t = 0.9 \\nindex = np.where(t_points == end_t)[0][0]\\nend_labels = Exact[index, :]\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CREDIT TO https://github.com/maziarraissi/PINNs/blob/master/appendix/discrete_time_inference%20(Burgers)/Burgers_systematic.py FOR THE BELOW CODE TO IMPORT IRK WEIGHTS AND THE LABEL DATA (AND FOR THE DATA ITSELF)\n",
    "\n",
    "tmp = np.float32(np.loadtxt('./data/Butcher_IRK%d.txt' % (q), ndmin = 2))\n",
    "IRK_weights = np.reshape(tmp[0:q**2+q], (q+1,q)) #presume the first q rows and q columns represent a_{ij} values, and the final row represents the b_j values\n",
    "IRK_times = tmp[q**2+q:] #not sure what this is used for\n",
    "\n",
    "\n",
    "#I may choose to generate my own data once more...\n",
    "'''\n",
    "data = scipy.io.loadmat('./data/burgers_shock.mat')\n",
    "\n",
    "t_points = data['t'].flatten()[:,None] # T x 1\n",
    "x_points = data['x'].flatten()[:,None] # N x 1\n",
    "Exact = np.real(data['usol']).T # T x N\n",
    "\n",
    "#get data labels at t = 0.9 \n",
    "index = np.where(t_points == end_t)[0][0]\n",
    "end_labels = Exact[index, :]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.random.rand(N) * 2 - 1 #x values between -1 and 1\n",
    "\n",
    "initial_vals = -np.sin(input * np.pi) #initial values at t = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.act_func = nn.Tanh()\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Linear(1, 50),\n",
    "            self.act_func,\n",
    "            nn.Linear(50, 50),\n",
    "            self.act_func,\n",
    "            nn.Linear(50, 50),\n",
    "            self.act_func,\n",
    "            nn.Linear(50, q + 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.predict(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nonelinear Burgers' Operator\n",
    "def NLO(input, outputs, device): #outputs is of the form N x q. Inputs is of form N x 1 and was used to get outputs\n",
    "\n",
    "\n",
    "    u = outputs\n",
    "    print(input.shape)\n",
    "    print(u.shape)\n",
    "\n",
    "    u_x = jacobian(lambda u,x: u, (u, input), create_graph=True, vectorize=True)\n",
    "\n",
    "    print(len(u_x))\n",
    "    print(u_x[0].shape)\n",
    "    print(u_x[1].shape)\n",
    "\n",
    "    u_x = u_x.squeeze(-1) #Jacobian with vectorize should return shape (N, q, 1)\n",
    "\n",
    "    u_xx = jacobian(lambda u_x, x: u_x, (u_x, input), create_graph=True, vectorize=True)\n",
    "\n",
    "    u_xx = u_xx.squeeze(-1)\n",
    "\n",
    "\n",
    "    return u * u_x - (0.01/torch.pi)*u_xx\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#Implicit Runge-Kutta Calculation (Combine Intermediate Terms with Butcher Tableau Coefficients)\n",
    "def IRK(input, outputs, initial_vals, coefficients, device): #outputs is tensor of size Nx(q+1), represnting q stages for N x-values and the final n+1 prediction. coefficients is a tensor of size (q+1) x q representing the Butcher Tableau. Input and initial_vals are size (N)\n",
    "\n",
    "    outputs_truncated = outputs[:, :-1] #get all but last row\n",
    "\n",
    "    global N\n",
    "    global q\n",
    "    global h\n",
    "\n",
    "\n",
    "    NLO_outputs = NLO(input, outputs_truncated, device) #perform non-linear operation on each of the outputs_truncated. Shape is still (N, q)\n",
    "    \n",
    "    N_coefficients = coefficients.repeat(N, 1, 1) #stack N coefficients tensors on top of each other\n",
    "    NLO_outputs = NLO_outputs.unsqueeze(-1) #reshape NLO_outputs_reshaped into shape (N, q, 1) for matrix multiplication\n",
    "\n",
    "    coefficients_applied = torch.bmm(N_coefficients, NLO_outputs) #perform matrix multiplication. This represents applying the coefficients a_{ij} (and b_i for n+1 prediction) from the Butcher Tableau to every element in NLO_outputs and THEN recombining them to make every new value which will go on to form the \"calculated\" outputs (intermediate stage values). Has shape (N, q+1, 1), since N_coefficients has shape (N, q+1, q) and NLO_outputs has shape (N, q, 1). For each layer in N, the matrix mulitplcaion (q+1, q) x (q, 1) takes place, resulting in a vector of shape (q+1, 1). N of these makes (N, q+1, 1)\n",
    "    coefficients_applied = coefficients_applied.view(N, -1) #now shape (N, q + 1)\n",
    "\n",
    "    coefficients_applied = -h * coefficients_applied #apply the -h (-\\delta t) to each element in coefficients_applied\n",
    "    initial_vals = initial_vals.view(-1, 1) #reshape initial_vals from (N) to (N, 1)\n",
    "\n",
    "    result = coefficients_applied + initial_vals #Every element in coefficients_applied has a value added to it which is the element from initial_vals on the same layer. We can add the shapes (N, q+1) and (N, 1) due to \"broadcasting\", which effectively stretches the shape of the vector\n",
    "\n",
    "    return result #returns a result which is the same shape as \"outputs\" and represents the same intermediate values, except these are the \"calculated\" versions and not the \"direct predictions\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSE_n(input, outputs, initial_vals, coefficients, device):\n",
    "\n",
    "    calculated_outputs = IRK(input, outputs, initial_vals, coefficients, device)\n",
    "\n",
    "    SSE_n_loss = torch.sum((calculated_outputs - outputs)**2)\n",
    "\n",
    "    return SSE_n_loss\n",
    "\n",
    "\n",
    "def SSE_b(network, device):\n",
    "    boundary_points = torch.tensor([-1, 1]).to(device).view(-1, 1)\n",
    "    boundary_results = network(boundary_points) #get all intermediary points and the n+1 prediction for x = -1 and 1\n",
    "    return torch.sum(boundary_results**2) #square results and sum them\n",
    "\n",
    "\n",
    "def SSE(input, outputs, initial_vals, coefficients, network, device):\n",
    "    SSE_n_loss = SSE_n(input, outputs, initial_vals, coefficients, device)\n",
    "    SSE_b_loss = SSE_b(network, device)\n",
    "    return SSE_n_loss + SSE_b_loss, SSE_n, SSE_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: CPU\n"
     ]
    }
   ],
   "source": [
    "pinn = PINN()\n",
    "optimizer = torch.optim.LBFGS(pinn.parameters(), #PARAMETERS CREDIT TO https://github.com/teeratornk/PINNs-2/blob/master/Burgers%20Equation/Burgers%20Inference%20(PyTorch).ipynb\n",
    "                              lr=1,\n",
    "                              max_iter=50000, \n",
    "                                max_eval=50000, \n",
    "                                history_size=50,\n",
    "                                tolerance_grad=1e-5, \n",
    "                                tolerance_change=1.0 * np.finfo(float).eps,\n",
    "                                line_search_fn=\"strong_wolfe\"\n",
    "                              )\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + (\"GPU\" if torch.cuda.is_available() else \"CPU\"))\n",
    "pinn.to(device)\n",
    "\n",
    "\n",
    "input = torch.tensor(input.astype(np.float32), requires_grad=True).to(device).view(-1, 1)\n",
    "initial_vals = torch.tensor(initial_vals.astype(np.float32)).to(device).view(-1, 1)\n",
    "coefficients = torch.tensor(IRK_weights.astype(np.float32)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n",
      "torch.Size([100, 500])\n",
      "2\n",
      "torch.Size([100, 500, 100, 500])\n",
      "torch.Size([100, 500, 100, 1])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'squeeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/alexning/Desktop/Life/UVA/Research/Research1 (Public Github repo)/PINN 2 - Implicit Runge-Kutta/IRKPINN.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m overall_loss\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep(closure)\n",
      "File \u001b[0;32m~/anaconda3/envs/env-1-ai/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/env-1-ai/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/env-1-ai/lib/python3.11/site-packages/torch/optim/lbfgs.py:312\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    309\u001b[0m state\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mn_iter\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[39m# evaluate initial f(x) and df/dx\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m orig_loss \u001b[39m=\u001b[39m closure()\n\u001b[1;32m    313\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(orig_loss)\n\u001b[1;32m    314\u001b[0m current_evals \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/env-1-ai/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32m/Users/alexning/Desktop/Life/UVA/Research/Research1 (Public Github repo)/PINN 2 - Implicit Runge-Kutta/IRKPINN.ipynb Cell 19\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad() \u001b[39m#reset the gradient so that the previous iteration does not affect the current one\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m outputs \u001b[39m=\u001b[39m pinn(\u001b[39minput\u001b[39m) \u001b[39m#run the batch through the current model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m overall_loss, SSE_n, SSE_b \u001b[39m=\u001b[39m SSE(\u001b[39minput\u001b[39m, outputs, initial_vals, coefficients, pinn, device) \u001b[39m#calculate the loss\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m overall_loss\u001b[39m.\u001b[39mbackward() \u001b[39m#Using backpropagation, calculate the gradients\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m#print(f\"Avg loss: {loss.item()}\")\u001b[39;00m\n",
      "\u001b[1;32m/Users/alexning/Desktop/Life/UVA/Research/Research1 (Public Github repo)/PINN 2 - Implicit Runge-Kutta/IRKPINN.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mSSE\u001b[39m(\u001b[39minput\u001b[39m, outputs, initial_vals, coefficients, network, device):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     SSE_n_loss \u001b[39m=\u001b[39m SSE_n(\u001b[39minput\u001b[39m, outputs, initial_vals, coefficients, device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     SSE_b_loss \u001b[39m=\u001b[39m SSE_b(network, device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m SSE_n_loss \u001b[39m+\u001b[39m SSE_b_loss, SSE_n, SSE_b\n",
      "\u001b[1;32m/Users/alexning/Desktop/Life/UVA/Research/Research1 (Public Github repo)/PINN 2 - Implicit Runge-Kutta/IRKPINN.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mSSE_n\u001b[39m(\u001b[39minput\u001b[39m, outputs, initial_vals, coefficients, device):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     calculated_outputs \u001b[39m=\u001b[39m IRK(\u001b[39minput\u001b[39m, outputs, initial_vals, coefficients, device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     SSE_n_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum((calculated_outputs \u001b[39m-\u001b[39m outputs)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m SSE_n_loss\n",
      "\u001b[1;32m/Users/alexning/Desktop/Life/UVA/Research/Research1 (Public Github repo)/PINN 2 - Implicit Runge-Kutta/IRKPINN.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mglobal\u001b[39;00m q\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mglobal\u001b[39;00m h\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m NLO_outputs \u001b[39m=\u001b[39m NLO(\u001b[39minput\u001b[39m, outputs_truncated, device) \u001b[39m#perform non-linear operation on each of the outputs_truncated. Shape is still (N, q)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m N_coefficients \u001b[39m=\u001b[39m coefficients\u001b[39m.\u001b[39mrepeat(N, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m#stack N coefficients tensors on top of each other\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m NLO_outputs \u001b[39m=\u001b[39m NLO_outputs\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m#reshape NLO_outputs_reshaped into shape (N, q, 1) for matrix multiplication\u001b[39;00m\n",
      "\u001b[1;32m/Users/alexning/Desktop/Life/UVA/Research/Research1 (Public Github repo)/PINN 2 - Implicit Runge-Kutta/IRKPINN.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(u_x[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(u_x[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m u_x \u001b[39m=\u001b[39m u_x\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m#Jacobian with vectorize should return shape (N, q, 1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m u_xx \u001b[39m=\u001b[39m jacobian(\u001b[39mlambda\u001b[39;00m u_x, x: u_x, (u_x, \u001b[39minput\u001b[39m), create_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, vectorize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alexning/Desktop/Life/UVA/Research/Research1%20%28Public%20Github%20repo%29/PINN%202%20-%20Implicit%20Runge-Kutta/IRKPINN.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m u_xx \u001b[39m=\u001b[39m u_xx\u001b[39m.\u001b[39msqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'squeeze'"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad() #reset the gradient so that the previous iteration does not affect the current one\n",
    "    outputs = pinn(input) #run the batch through the current model\n",
    "    \n",
    "    overall_loss, SSE_n, SSE_b = SSE(input, outputs, initial_vals, coefficients, pinn, device) #calculate the loss\n",
    "    overall_loss.backward() #Using backpropagation, calculate the gradients\n",
    "    #print(f\"Avg loss: {loss.item()}\")\n",
    "\n",
    "    global i\n",
    "    if i%100 == 0:\n",
    "        print(f\"STEP: {i} | Avg Losses | SSE_n: {SSE_n.item()} | SSE_b: {SSE_b.item()} | Total: {overall_loss.item()}\")\n",
    "    i += 1\n",
    "\n",
    "    return overall_loss\n",
    "\n",
    "optimizer.step(closure) #Using the gradients, adjust the parameters   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-1-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
