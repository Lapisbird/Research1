{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts:\n",
    "\n",
    "I had a theory: The model is incentivised to create a flat plane to minimize f(t,x). This way u, u_t, u_x, and u_xx are all close to 0. Additionally, since boundary points at x = = -1, 1 all have the same value (0), a flat plane wouldn't hurt either. It is the easiest way. This theory worked. Until I made all the data points the ones at t = 0 and completely took away the MSE_f loss component. Still, a flat plane appeared. Still, the derivatives died. Less than before. But given that the ONLY job of the entire network at this point was to approximate -sin(x*\\pi), it is but a bit concerning that it is STILL unable to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn \n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "import pyDOE2\n",
    "from torch.autograd.functional import jacobian, hessian\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bounds = [-1, 1]\n",
    "t_bounds = [0, 1]\n",
    "num_data_points = 200\n",
    "num_collocation_points = 10000\n",
    "proportion_t_0 = 1 #the proportion of the data points which will exist at various points x along the boundary t = 0. The rest will be split between the boundaries x = -1 and x = 1 for all t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_t_0 = (int) (num_data_points * proportion_t_0)\n",
    "num_points_x_1 = (num_data_points - num_points_t_0)//2 # // is integer division\n",
    "num_points_x_neg_1 = num_data_points - num_points_t_0 - num_points_x_1\n",
    "\n",
    "#create num_data_points random data points on the boundaries of the PDE\n",
    "t_0_points = np.array( list( zip(np.zeros(num_points_t_0), 2 * np.random.rand(num_points_t_0) - 1 ) ) )\n",
    "x_1_points = np.array( list( zip(np.random.rand(num_points_x_1), np.full(num_points_x_1, 1)) ) ) #np.full() takes paramters shape, value. Shape can be a tuple for multidimensional arrays filled with value.\n",
    "x_neg_1_points = np.array( list( zip(np.random.rand(num_points_x_neg_1), np.full(num_points_x_neg_1, -1)) ) )\n",
    "x_points = np.concatenate(( x_1_points, x_neg_1_points ))\n",
    "\n",
    "#Generating labels with the data\n",
    "dtype = [('points', float, 2), ('label', float)] #need custom dtype because otherwise numpy doesn't like these combined arrays\n",
    "\n",
    "t_0_labels = -np.sin(np.pi * t_0_points[:,1] )\n",
    "t_0_combined = np.array(list( zip(t_0_points, t_0_labels) ), dtype=dtype)\n",
    "\n",
    "x_labels = np.zeros(num_points_x_1 + num_points_x_neg_1)\n",
    "x_combined = np.array(list( zip(x_points, x_labels) ), dtype=dtype)\n",
    "\n",
    "combined_labels_data = np.concatenate( (t_0_combined, x_combined) )\n",
    "\n",
    "np.random.shuffle(combined_labels_data)\n",
    "\n",
    "data_points, labels = map(np.array, map(list, zip(*combined_labels_data)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Validation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Test 1: Ensure all data points lie on the correct boundaries\\ndef test_boundaries(data_points):\\n    t_values = data_points[:, 0]\\n    x_values = data_points[:, 1]\\n    assert np.all((t_values == 0) | (x_values == 1) | (x_values == -1)), \"Some points do not lie on the correct boundaries.\"\\n\\ntest_boundaries(data_points)\\nprint(\"Test 1 passed!\")\\n\\n# Test 2: For t=0, label should be -sin(pi * x)\\ndef test_labels_t_0(data_points, labels):\\n    mask_t_0 = data_points[:, 0] == 0\\n    expected_labels = -np.sin(np.pi * data_points[mask_t_0, 1])\\n    assert np.allclose(labels[mask_t_0], expected_labels), \"Labels for t=0 do not match -sin(pi * x).\"\\n\\ntest_labels_t_0(data_points, labels)\\nprint(\"Test 2 passed!\")\\n\\n# Test 3: For x=-1 or x=1, label should be 0\\ndef test_labels_x_boundaries(data_points, labels):\\n    mask_x_boundaries = (data_points[:, 1] == 1) | (data_points[:, 1] == -1)\\n    assert np.all(labels[mask_x_boundaries] == 0), \"Labels for x=-1 or x=1 are not zero.\"\\n\\ntest_labels_x_boundaries(data_points, labels)\\nprint(\"Test 3 passed!\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Test 1: Ensure all data points lie on the correct boundaries\n",
    "def test_boundaries(data_points):\n",
    "    t_values = data_points[:, 0]\n",
    "    x_values = data_points[:, 1]\n",
    "    assert np.all((t_values == 0) | (x_values == 1) | (x_values == -1)), \"Some points do not lie on the correct boundaries.\"\n",
    "\n",
    "test_boundaries(data_points)\n",
    "print(\"Test 1 passed!\")\n",
    "\n",
    "# Test 2: For t=0, label should be -sin(pi * x)\n",
    "def test_labels_t_0(data_points, labels):\n",
    "    mask_t_0 = data_points[:, 0] == 0\n",
    "    expected_labels = -np.sin(np.pi * data_points[mask_t_0, 1])\n",
    "    assert np.allclose(labels[mask_t_0], expected_labels), \"Labels for t=0 do not match -sin(pi * x).\"\n",
    "\n",
    "test_labels_t_0(data_points, labels)\n",
    "print(\"Test 2 passed!\")\n",
    "\n",
    "# Test 3: For x=-1 or x=1, label should be 0\n",
    "def test_labels_x_boundaries(data_points, labels):\n",
    "    mask_x_boundaries = (data_points[:, 1] == 1) | (data_points[:, 1] == -1)\n",
    "    assert np.all(labels[mask_x_boundaries] == 0), \"Labels for x=-1 or x=1 are not zero.\"\n",
    "\n",
    "test_labels_x_boundaries(data_points, labels)\n",
    "print(\"Test 3 passed!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN_DataSet(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "trainset = PINN_DataSet(data_points.astype(np.float32), labels.astype(np.float32)) #convert to float32, or else later the resulting torch tensors will be of torch.float64 type, which is not compatible with the neural network\n",
    "\n",
    "batch_size = num_data_points #no mini-batches\n",
    "#batch_size = 250\n",
    "\n",
    "num_workers = 0\n",
    "\n",
    "trainloader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = num_workers\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collocation Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lhs_samples(n): #generate n collocation points via Latin Hypercube Sampling. Each point is a (t,x)\n",
    "    lhs_array = pyDOE2.lhs(2, samples=n) #Two dimensions. Values from 0 to 1\n",
    "    lhs_array[:,1] = 2*lhs_array[:,1] - 1 #convert range of x values to -1 to 1\n",
    "    return lhs_array\n",
    "\n",
    "collocation_points = lhs_samples(num_collocation_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class PINN(nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n        self.net = nn.Sequential( #9 layers of 20 neurons each\\n            nn.Linear(2,20),\\n            nn.Tanh(),\\n            nn.Linear(20,20),\\n            nn.Tanh(),\\n            nn.Linear(20,20),\\n            nn.Tanh(),\\n            nn.Linear(20,20),\\n            nn.Tanh(),\\n            nn.Linear(20,20),\\n            nn.Tanh(),\\n            nn.Linear(20,20),\\n            nn.Tanh(),\\n            nn.Linear(20,20),\\n            nn.Tanh(),\\n            nn.Linear(20,20),\\n            nn.Tanh(),\\n            nn.Linear(20,20),\\n            nn.Tanh(),\\n            nn.Linear(20,20),\\n            nn.Tanh(),\\n            nn.Linear(20,1),\\n            #nn.Tanh()\\n\\n        )\\n\\n    def forward(self, x):\\n        return self.net(x)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential( #9 layers of 20 neurons each\n",
    "            nn.Linear(2,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20,1),\n",
    "            #nn.Tanh()\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential( #9 layers of 20 neurons each\n",
    "            nn.Linear(2,100),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(100,100),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(100,100),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(100,100),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(100,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_f(collocation_points, neural_network, device): #I need to better understand how exactly autograd handles vectorization. I think I just waste 6 hours on a wild goose chase due to a misconception about that very fact...\n",
    "\n",
    "    collocation_inputs = torch.tensor(collocation_points.astype(np.float32), requires_grad=True).to(device)\n",
    "    \n",
    "    u = neural_network(collocation_inputs)\n",
    "    results, = torch.autograd.grad(u, collocation_inputs, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)\n",
    "    u_t = results[:,0]\n",
    "    u_x = results[:,1]\n",
    "    snd_result, = torch.autograd.grad(u_x, collocation_inputs, grad_outputs=torch.ones_like(u_x), retain_graph=True, create_graph=True)\n",
    "    u_xx = snd_result[:,1]\n",
    "    print(f\"u: {u[:5]}\")\n",
    "    print(f\"u_t: {u_t[:5]}\")\n",
    "    print(f\"u_x: {u_x[:5]}\")\n",
    "    print(f\"u_xx: {u_xx[:5]}\")\n",
    "    final_result = torch.mean((u_t + u*u_x - (0.01/torch.pi)*u_xx)**2)\n",
    "    print(f\"Result: {final_result}\")\n",
    "    return final_result\n",
    "    \n",
    "def MSE_u(output, label):\n",
    "    return torch.mean((output - label)**2)\n",
    "\n",
    "\n",
    "def criterion(output, label, collocation_points, neural_network, device):\n",
    "    #mse_u = nn.MSELoss()(output, label).squeeze()\n",
    "    mse_u = MSE_u(output, label).squeeze()\n",
    "    mse_f = MSE_f(collocation_points, neural_network, device).squeeze()\n",
    "    return  mse_u + 0*mse_f, mse_u.item(), mse_f.item()\n",
    "    #return 10*(mse_u + mse_f), mse_u.item(), mse_f.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: CPU\n",
      "EPOCH 1 out of 50\n",
      "u: tensor([[-0.1131],\n",
      "        [-0.1120],\n",
      "        [-0.1134],\n",
      "        [-0.1027],\n",
      "        [-0.1052]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0175, 0.0184, 0.0184, 0.0085, 0.0140], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([0.0248, 0.0209, 0.0233, 0.0255, 0.0164], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0081, 0.0084, 0.0085, 0.0049, 0.0084], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00021883966110181063\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4870645999908447\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00021883966110181063\n",
      "u: tensor([[-0.0899],\n",
      "        [-0.0892],\n",
      "        [-0.0903],\n",
      "        [-0.0793],\n",
      "        [-0.0829]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0157, 0.0163, 0.0165, 0.0066, 0.0113], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([0.0262, 0.0225, 0.0249, 0.0258, 0.0175], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0051, 0.0058, 0.0057, 0.0019, 0.0062], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00019688111206050962\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4803416132926941\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00019688111206050962\n",
      "u: tensor([[0.0396],\n",
      "        [0.0384],\n",
      "        [0.0385],\n",
      "        [0.0499],\n",
      "        [0.0414]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([ 0.0055,  0.0042,  0.0058, -0.0044, -0.0039], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([0.0304, 0.0274, 0.0298, 0.0236, 0.0203], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([-0.0118, -0.0091, -0.0105, -0.0146, -0.0057], grad_fn=<SliceBackward0>)\n",
      "Result: 0.000155805260874331\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4628182649612427\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.000155805260874331\n",
      "u: tensor([[0.0430],\n",
      "        [0.0420],\n",
      "        [0.0421],\n",
      "        [0.0518],\n",
      "        [0.0443]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([ 0.0049,  0.0035,  0.0051, -0.0047, -0.0046], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([0.0266, 0.0237, 0.0259, 0.0198, 0.0167], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([-0.0124, -0.0097, -0.0111, -0.0144, -0.0058], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00014735061267856508\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4627247154712677\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00014735061267856508\n",
      "u: tensor([[0.0523],\n",
      "        [0.0523],\n",
      "        [0.0522],\n",
      "        [0.0519],\n",
      "        [0.0509]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([ 0.0021,  0.0002,  0.0021, -0.0059, -0.0075], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([ 0.0028,  0.0005,  0.0024, -0.0036, -0.0052], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([-0.0143, -0.0119, -0.0134, -0.0114, -0.0055], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00010627080337144434\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46243008971214294\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00010627080337144434\n",
      "u: tensor([[0.0505],\n",
      "        [0.0510],\n",
      "        [0.0508],\n",
      "        [0.0472],\n",
      "        [0.0485]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([ 0.0016, -0.0003,  0.0015, -0.0059, -0.0078], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0053, -0.0073, -0.0056, -0.0111, -0.0126], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([-0.0143, -0.0120, -0.0135, -0.0098, -0.0049], grad_fn=<SliceBackward0>)\n",
      "Result: 9.469909127801657e-05\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4623926877975464\n",
      "Avg f(t,x)^2 Per Collocation Point: 9.469909127801657e-05\n",
      "u: tensor([[0.0501],\n",
      "        [0.0507],\n",
      "        [0.0505],\n",
      "        [0.0467],\n",
      "        [0.0481]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([ 0.0016, -0.0003,  0.0015, -0.0058, -0.0078], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0057, -0.0077, -0.0060, -0.0115, -0.0130], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([-0.0142, -0.0119, -0.0134, -0.0096, -0.0048], grad_fn=<SliceBackward0>)\n",
      "Result: 9.393440268468112e-05\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4623923897743225\n",
      "Avg f(t,x)^2 Per Collocation Point: 9.393440268468112e-05\n",
      "u: tensor([[0.0501],\n",
      "        [0.0507],\n",
      "        [0.0504],\n",
      "        [0.0466],\n",
      "        [0.0481]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([ 0.0017, -0.0003,  0.0016, -0.0058, -0.0077], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0057, -0.0077, -0.0060, -0.0115, -0.0130], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([-0.0142, -0.0119, -0.0134, -0.0096, -0.0048], grad_fn=<SliceBackward0>)\n",
      "Result: 9.387746104039252e-05\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4623923897743225\n",
      "Avg f(t,x)^2 Per Collocation Point: 9.387746104039252e-05\n",
      "EPOCH 2 out of 50\n",
      "u: tensor([[0.0501],\n",
      "        [0.0507],\n",
      "        [0.0504],\n",
      "        [0.0466],\n",
      "        [0.0481]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([ 0.0017, -0.0003,  0.0016, -0.0058, -0.0077], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0057, -0.0077, -0.0060, -0.0115, -0.0130], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([-0.0142, -0.0119, -0.0134, -0.0096, -0.0048], grad_fn=<SliceBackward0>)\n",
      "Result: 9.387746104039252e-05\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4623923897743225\n",
      "Avg f(t,x)^2 Per Collocation Point: 9.387746104039252e-05\n",
      "u: tensor([[0.0499],\n",
      "        [0.0505],\n",
      "        [0.0503],\n",
      "        [0.0465],\n",
      "        [0.0480]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([ 0.0018, -0.0002,  0.0017, -0.0057, -0.0076], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0057, -0.0077, -0.0060, -0.0114, -0.0130], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([-0.0139, -0.0117, -0.0132, -0.0094, -0.0046], grad_fn=<SliceBackward0>)\n",
      "Result: 9.350780601380393e-05\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46239224076271057\n",
      "Avg f(t,x)^2 Per Collocation Point: 9.350780601380393e-05\n",
      "u: tensor([[0.0498],\n",
      "        [0.0504],\n",
      "        [0.0501],\n",
      "        [0.0463],\n",
      "        [0.0479]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([ 2.0194e-03,  9.2794e-05,  1.9277e-03, -5.4235e-03, -7.2905e-03],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0058, -0.0078, -0.0061, -0.0113, -0.0130], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([-0.0135, -0.0113, -0.0128, -0.0090, -0.0043], grad_fn=<SliceBackward0>)\n",
      "Result: 9.281296661356464e-05\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46239200234413147\n",
      "Avg f(t,x)^2 Per Collocation Point: 9.281296661356464e-05\n",
      "u: tensor([[0.0495],\n",
      "        [0.0503],\n",
      "        [0.0499],\n",
      "        [0.0461],\n",
      "        [0.0480]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([ 0.0027,  0.0009,  0.0027, -0.0047, -0.0064], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0060, -0.0081, -0.0064, -0.0111, -0.0131], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([-0.0121, -0.0101, -0.0115, -0.0077, -0.0033], grad_fn=<SliceBackward0>)\n",
      "Result: 9.126905933953822e-05\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4623914957046509\n",
      "Avg f(t,x)^2 Per Collocation Point: 9.126905933953822e-05\n",
      "u: tensor([[0.0494],\n",
      "        [0.0504],\n",
      "        [0.0499],\n",
      "        [0.0461],\n",
      "        [0.0486]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([ 0.0043,  0.0025,  0.0043, -0.0030, -0.0045], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0067, -0.0089, -0.0072, -0.0106, -0.0134], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([-0.0091, -0.0075, -0.0086, -0.0049, -0.0012], grad_fn=<SliceBackward0>)\n",
      "Result: 9.057912393473089e-05\n",
      "Avg MSE Loss Per Boundary Data Point: 0.462390273809433\n",
      "Avg f(t,x)^2 Per Collocation Point: 9.057912393473089e-05\n",
      "u: tensor([[0.0497],\n",
      "        [0.0512],\n",
      "        [0.0504],\n",
      "        [0.0465],\n",
      "        [0.0502]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([ 0.0073,  0.0057,  0.0072,  0.0002, -0.0010], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0080, -0.0104, -0.0087, -0.0098, -0.0141], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([-0.0036, -0.0026, -0.0034,  0.0004,  0.0028], grad_fn=<SliceBackward0>)\n",
      "Result: 9.920293086906895e-05\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238836646080017\n",
      "Avg f(t,x)^2 Per Collocation Point: 9.920293086906895e-05\n",
      "u: tensor([[0.0508],\n",
      "        [0.0529],\n",
      "        [0.0517],\n",
      "        [0.0476],\n",
      "        [0.0527]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0104, 0.0090, 0.0105, 0.0036, 0.0028], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0096, -0.0122, -0.0105, -0.0091, -0.0150], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0023, 0.0026, 0.0022, 0.0060, 0.0070], grad_fn=<SliceBackward0>)\n",
      "Result: 0.0001228101464221254\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238651871681213\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.0001228101464221254\n",
      "u: tensor([[0.0513],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0535]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0109, 0.0095, 0.0110, 0.0042, 0.0034], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0100, -0.0126, -0.0109, -0.0091, -0.0152], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0032, 0.0034, 0.0031, 0.0069, 0.0076], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012768220040015876\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238622069358826\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012768220040015876\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0524],\n",
      "        [0.0482],\n",
      "        [0.0533]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0104, 0.0090, 0.0104, 0.0037, 0.0028], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0098, -0.0124, -0.0107, -0.0093, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0023, 0.0026, 0.0022, 0.0061, 0.0070], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012253475142642856\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238622069358826\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012253475142642856\n",
      "EPOCH 3 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0524],\n",
      "        [0.0482],\n",
      "        [0.0533]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0104, 0.0090, 0.0104, 0.0037, 0.0028], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0098, -0.0124, -0.0107, -0.0093, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0023, 0.0026, 0.0022, 0.0061, 0.0070], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012253475142642856\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238622069358826\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012253475142642856\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 4 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238622069358826\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 5 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 6 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 7 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 8 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4623861312866211\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 9 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 10 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 11 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 12 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4623861312866211\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 13 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4623861312866211\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 14 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 15 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4623861312866211\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 16 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 17 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 18 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 19 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238622069358826\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 20 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238622069358826\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 21 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 22 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 23 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238622069358826\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 24 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238622069358826\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 25 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 26 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4623861312866211\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 27 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4623861312866211\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 28 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 29 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4623861312866211\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 30 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 31 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 32 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238622069358826\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 33 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 34 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238622069358826\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 35 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 36 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 37 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 38 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4623861312866211\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 39 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 40 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4623861312866211\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 41 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 42 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 43 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 44 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 45 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 46 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 47 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 48 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 49 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.46238619089126587\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "EPOCH 50 out of 50\n",
      "u: tensor([[0.0514],\n",
      "        [0.0535],\n",
      "        [0.0523],\n",
      "        [0.0482],\n",
      "        [0.0532]], grad_fn=<SliceBackward0>)\n",
      "u_t: tensor([0.0102, 0.0087, 0.0102, 0.0034, 0.0025], grad_fn=<SliceBackward0>)\n",
      "u_x: tensor([-0.0097, -0.0122, -0.0106, -0.0094, -0.0151], grad_fn=<SliceBackward0>)\n",
      "u_xx: tensor([0.0018, 0.0022, 0.0018, 0.0056, 0.0066], grad_fn=<SliceBackward0>)\n",
      "Result: 0.00012018749112030491\n",
      "Avg MSE Loss Per Boundary Data Point: 0.4623861312866211\n",
      "Avg f(t,x)^2 Per Collocation Point: 0.00012018749112030491\n",
      "TRAINING COMPLETE!\n"
     ]
    }
   ],
   "source": [
    "pinn = PINN()\n",
    "optimizer = torch.optim.LBFGS(pinn.parameters(), #PARAMETERS CREDIT TO https://github.com/teeratornk/PINNs-2/blob/master/Burgers%20Equation/Burgers%20Inference%20(PyTorch).ipynb\n",
    "                              lr=1.0,\n",
    "                              max_iter=50000, \n",
    "                                max_eval=50000, \n",
    "                                history_size=50,\n",
    "                                tolerance_grad=1e-5, \n",
    "                                tolerance_change=1.0 * np.finfo(float).eps,\n",
    "                                line_search_fn=\"strong_wolfe\"\n",
    "                              )\n",
    "\n",
    "num_epochs = 50 #I have no idea how many epochs were used in the paper's implementation. Let's just do a lot for now and see how quickly training converges\n",
    "\n",
    "#use the GPU to train if possible, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + (\"GPU\" if torch.cuda.is_available() else \"CPU\"))\n",
    "pinn.to(device)\n",
    "\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print(f\"EPOCH {epoch + 1} out of {num_epochs}\")\n",
    "        train_running_loss = 0\n",
    "\n",
    "\n",
    "        for data in trainloader:\n",
    "\n",
    "            input, label = data #input and label already seem to be tensors. Tbh, I am a little confused when this happened. I don't think I ever explicitly turned them into tensors. They used to both be numpy arrays. EDIT: Further research seems to show that dataloader does this automatically as it fetches data from the dataset\n",
    "            input = input.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "\n",
    "            def closure():\n",
    "                optimizer.zero_grad() #reset the gradient so that the previous iteration does not affect the current one\n",
    "                output = pinn(input) #run the batch through the current model\n",
    "                loss, mse_u, mse_f = criterion(output, label, collocation_points, pinn, device) #calculate the loss\n",
    "                loss.backward() #Using backpropagation, calculate the gradients\n",
    "                print(f\"Avg MSE Loss Per Boundary Data Point: {mse_u}\")\n",
    "                print(f\"Avg f(t,x)^2 Per Collocation Point: {mse_f}\")\n",
    "                return loss\n",
    "\n",
    "            optimizer.step(closure) #Using the gradients, adjust the parameters    \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted by user.\")  \n",
    "\n",
    "print(\"TRAINING COMPLETE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "base_path = \"./\"\n",
    "base_name = \"pinn_model\"\n",
    "extension = \".pth\"\n",
    "\n",
    "counter = 0\n",
    "model_save_path = os.path.join(base_path, base_name + extension)\n",
    "\n",
    "while os.path.exists(model_save_path):\n",
    "    counter += 1\n",
    "    model_save_path = os.path.join(base_path, f\"{base_name}_{counter}{extension}\")\n",
    "\n",
    "torch.save(pinn.state_dict(), model_save_path)\n",
    "\n",
    "print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Generate Random Points\n",
    "num_points = 1000000\n",
    "t_values = np.random.rand(num_points)\n",
    "x_values = np.random.uniform(-1, 1, num_points)\n",
    "points = np.vstack((t_values, x_values)).T\n",
    "points_tensor = torch.tensor(points, dtype=torch.float32).to(device)\n",
    "\n",
    "# 2. Feed the Points through the Model\n",
    "with torch.no_grad():\n",
    "    model_outputs = pinn(points_tensor).cpu().numpy()\n",
    "    #print(model_outputs)\n",
    "\n",
    "# Normalize the model outputs to be between 0 and 1 for color mapping\n",
    "normalized_outputs = (model_outputs - (-1)) / (1 - (-1))\n",
    "\n",
    "# 3. Color Mapping\n",
    "colors = plt.cm.gray(normalized_outputs.squeeze()) # Change to grayscale\n",
    "\n",
    "# 4. Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(t_values, x_values, c=colors, s=1, alpha=0.5)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Visualization of Model Outputs\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-1-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
